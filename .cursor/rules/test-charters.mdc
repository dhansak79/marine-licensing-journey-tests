---
description: when creating test charters, planning investigative testing sessions, designing session-based test management, or structuring exploratory testing activities
globs: 
alwaysApply: false
---
# Test Charter Creation and Enhanced Testing Methodology

## Charter Philosophy: Beyond Traditional Test Cases

### **Theme-Based Charter Design**
- **Focus on testing themes** rather than individual user stories
- **One theme per charter** - single testing concern (novice experience, efficiency, form behaviour)
- **Cross-feature coverage** - test multiple delivered features together in realistic workflows
- **Persona alignment** - themes should clearly serve specific user types and their needs
- **Delivered features focus** - test what exists, not what's planned

### **Scenario Testing Integration**
Our test charters implement both **traditional Session-Based Test Management (SBTM)** and **Michael Bolton's scenario testing framework**. This dual approach provides:

- **Technical validation** through traditional SBTM charters
- **Realistic user investigation** through scenario-enhanced charters  
- **Comprehensive coverage** from multiple perspectives
- **Evidence quality** for both functional issues and user experience insights

### **Breaking the Test Case Addiction**
Following Bolton's principles, our scenario-enhanced charters:
- Replace predetermined steps with **guided realistic investigation**
- Focus on **authentic user pressures** rather than idealised conditions
- Use **rich oracles** to detect quality problems that binary pass/fail misses
- Investigate **how well features serve real users** under authentic conditions

## Core Charter Structure

### **Directory Organization**
- Test charters are organized in `test-charters/` at repository root
- Each user story gets its own subdirectory: `ML-{number}/`
- Charter files follow enhanced naming pattern: `ML-{number}-{type}-{aspect}.md`

### **Enhanced Charter Naming Convention**
```
Traditional SBTM Charters:
ML-{UserStoryNumber}-{TestingAspect}.md

Scenario-Enhanced Charters:
ML-{UserStoryNumber}-{PersonaName}-{Scenario}.md

Examples:
Traditional:
- ML-1-happy-path.md         (Core functionality validation)
- ML-1-validation.md         (Error handling and edge cases)
- ML-1-accessibility.md      (Inclusive design validation)

Scenario-Enhanced:
- ML-1-zofia-first-timer.md     (Novice user realistic journey)
- ML-1-amy-efficiency.md        (Veteran user speed patterns)
- ML-9-fatima-interruptions.md  (Case officer multitasking)
- ML-12-privacy-concerns.md     (Privacy decision under pressure)
```

### **Dual Charter Types**

#### **Traditional SBTM Charters (60-90 minutes)**
Standard exploratory testing for focused technical investigation:
```
EXPLORE: [Area of the application]
WITH: [Tools, data, personas, techniques]  
TO DISCOVER: [Types of information, risks, problems]

Duration: [60-90 minutes]
Priority: [High/Medium/Low based on risk]
Charter Type: Traditional SBTM Investigation
User Personas: [Which personas to consider]
```

#### **Scenario-Enhanced Charters (90-120 minutes)**
Rich, realistic user investigation using Bolton's framework:
```
CHARTER: [Investigation mission]

SCENARIO CONTEXT:
THEME: [Clear mission about realistic user situation]
SETUP: [Authentic user context, pressures, environment]
REALISTIC PRESSURES: [Interruptions, time pressure, friction]

ACTIVITIES: [Guided but flexible realistic actions]
ORACLES: [How to recognise problems and quality indicators]
VARIATIONS: [Ways to introduce turbulence and stress]

Duration: [90-120 minutes]
Charter Type: Scenario-Enhanced Investigation  
User Personas: [Primary persona with authentic context]
```

## Scenario Testing Methodology

### **Bolton's Framework Elements**

#### **THEME**
- Clear mission statement about realistic user situation
- Focus on authentic problems users actually face
- Connect to business value and user outcomes

#### **SETUP** 
- Authentic user context, environment, and pressures
- Realistic device configurations and constraints
- Genuine emotional and situational pressures

#### **ACTIVITIES**
- Guided but flexible realistic actions
- Adapt to discoveries while maintaining authenticity
- Focus on what users would actually do, not ideal paths

#### **ORACLES**
- Multiple quality indicators beyond functional correctness
- User experience signals and warning signs
- Business value and efficiency indicators

#### **VARIATIONS**
- Introduce realistic turbulence and stress
- Test system behaviour under authentic pressure
- Explore edge cases through realistic scenarios

### **Marine Licensing Scenario Elements**

#### **Realistic Pressures**
- **Time pressure** - Seasonal deadlines, end-of-day urgency
- **Interruptions** - Phone calls, emails, colleague questions
- **Technical friction** - Slow connections, device switching, browser issues
- **Cognitive load** - Complex regulations, unfamiliar terminology, multiple tasks
- **Environmental factors** - Office noise, mobile usage, assistive technology

#### **Authentic User Contexts**
- **Zofia scenarios** - First-time confusion, assistive technology, terminology barriers
- **Amy scenarios** - Efficiency focus, keyboard shortcuts, data reuse expectations
- **Fatima scenarios** - Multitasking pressure, interruptions, data integrity concerns
- **Simon scenarios** - Technical review focus, compliance validation, field access needs

#### **Evidence Collection Frameworks**
- **User journey evidence** - Decision points, friction, cognitive load, help-seeking
- **Technical evidence** - Performance, reliability, integration, data integrity
- **Content evidence** - Language clarity, guidance effectiveness, example quality
- **Problem classification** - Critical, significant, improvement opportunities

## Charter Selection Strategy

### **When to Use Traditional SBTM**
- **Quick technical validation** - Does functionality work as specified?
- **Cross-browser compatibility** - Consistent behaviour across platforms
- **Performance baselines** - How fast should operations be?
- **Edge case discovery** - What happens with unusual but valid inputs?
- **Focused investigations** - Specific technical areas need validation

### **When to Use Scenario-Enhanced**
- **Realistic user experience** - How does this work under authentic conditions?
- **Usability discovery** - What causes confusion or friction for real users?
- **Accessibility reality** - How does assistive technology work in real usage?
- **Content effectiveness** - Does guidance actually help or create confusion?
- **Workflow integration** - How does this step feel within complete user journeys?

### **Risk-Based Selection**
- **High-risk functionality** ‚Üí Scenario + Traditional charter combination
- **Medium-risk functionality** ‚Üí Traditional first, scenario follow-up if issues found
- **Low-risk functionality** ‚Üí Traditional charter focus

### **Time-Based Selection**
- **Short sessions (60 minutes)** ‚Üí Traditional SBTM charters
- **Standard sessions (90 minutes)** ‚Üí Traditional or lightweight scenarios  
- **Extended sessions (120+ minutes)** ‚Üí Full scenario investigations

## Maintenance Requirements

### **Enhanced Charter Status Table**
The `test-charters/README.md` must maintain accurate status for both charter types:

Required table format:
```markdown
| User Story | Charter Type | Charter Name | Priority | Status |
| ---------- | ------------ | ------------ | -------- | ------ |
| ML-X | Traditional | [Charter Name](mdc:marine-licensing-journey-tests/marine-licensing-journey-tests/ML-X/ML-X-aspect.md) | High | ‚úÖ Ready |
| ML-X | Scenario | [Scenario Name](mdc:marine-licensing-journey-tests/marine-licensing-journey-tests/ML-X/ML-X-persona-scenario.md) | High | üîÑ Draft |
```

Status indicators:
- ‚úÖ Ready: Charter complete and ready for use
- üîÑ Draft: Charter exists but needs refinement  
- ‚ùå Blocked: Charter cannot be completed due to dependencies

### **Dual Session Hopper Management**

#### **Traditional SBTM Hopper**
Quick-focus technical investigations (60-90 minutes):
- Functional validation sessions
- Cross-browser compatibility testing
- Performance and reliability validation
- Edge case and error handling investigation

#### **Scenario-Enhanced Hopper**  
Rich, realistic user investigations (90-120 minutes):
- Persona-driven authentic user journeys
- Realistic pressure and interruption testing
- Cross-device and accessibility scenarios
- Privacy and decision-making investigations

### **Charter Organization Section**
Must maintain clear separation and cross-referencing:
- Group by user story with charter type subsections
- Show complementary relationships between traditional and scenario charters
- Provide clear guidance on when to use each type

## Quality Standards

### **Traditional Charter Completeness**
- Clear technical exploration objective
- Specific tools and testing techniques
- Target discoveries and risk areas
- Realistic duration estimate (60-90 minutes)
- Appropriate persona consideration for usability insights

### **Scenario Charter Completeness**
- Authentic theme and user situation
- Realistic setup with genuine pressures
- Guided but flexible activities
- Rich oracles for quality detection
- Meaningful variations and turbulence
- Evidence collection framework
- Realistic duration estimate (90-120 minutes)

### **Cross-Charter Integration**
- Traditional charters reference complementary scenario investigations
- Scenario charters reference technical validation needs
- Clear follow-up guidance between charter types
- Integration with automation implications

## File Management Rules

### **When Adding New User Stories**
1. Create new directory: `test-charters/ML-{number}/`
2. Plan both traditional and scenario charter coverage
3. Add traditional charters for core technical validation
4. Add scenario charters for high-risk or complex user interactions
5. Update Charter Status table with both charter types
6. Update Charter Organisation section with clear type separation
7. Add relevant sessions to both traditional and scenario hoppers

### **When Planning Charter Coverage**
1. **Start with risk assessment** - Which user story aspects need deep investigation?
2. **Traditional first** - Basic functional validation using SBTM
3. **Scenario enhancement** - Add realistic user investigation for complex/risky areas
4. **Consider persona needs** - Which personas face the most significant challenges?
5. **Plan integration** - How do traditional and scenario findings complement each other?

### **When Updating Charter Framework**
1. Ensure both traditional and scenario templates are current
2. Update methodology guidance based on team learning
3. Maintain clear distinction between charter types
4. Keep integration guidance current and practical

## Integration Requirements

### **User Story Traceability**
- Charter names clearly reference user story numbers and types
- Charter content aligns with user story acceptance criteria
- Priority reflects user story business value and risk
- Traditional charters focus on acceptance criteria validation
- Scenario charters explore realistic usage of acceptance criteria

### **Enhanced Persona Integration**
Each charter type leverages personas differently:

#### **Traditional Charters**
- Consider persona needs for usability insights
- Include persona-specific test data and approaches
- Note persona-relevant discovery areas

#### **Scenario Charters**  
- Deep persona authenticity throughout investigation
- Realistic pressures and contexts for specific personas
- Persona-driven activities and variations
- Evidence collection focused on persona experience

### **Testing Strategy Alignment**
- Traditional charters provide technical validation baseline
- Scenario charters explore realistic user experience depth
- Charter combination provides comprehensive coverage
- Findings feed into automation strategy and design improvements

## Validation Checklist

Before committing charter changes:
- [ ] All table links work correctly for both charter types
- [ ] Charter Status table includes charter type column
- [ ] Charter Organisation section separates traditional and scenario types  
- [ ] Session Hopper includes both traditional and scenario options
- [ ] New traditional charters follow SBTM structure
- [ ] New scenario charters follow Bolton's framework
- [ ] File naming follows established convention for charter types
- [ ] Cross-references between complementary charter types are included
- [ ] Priority levels appropriate for business risk and investigation depth
- [ ] Integration guidance connects charter types effectively

## Evidence and Learning Integration

### **Traditional Charter Evidence**
- Functional correctness and technical validation
- Performance benchmarks and reliability data
- Cross-browser compatibility results
- Edge case and error handling effectiveness

### **Scenario Charter Evidence**
- Realistic user experience quality
- Content and guidance effectiveness  
- Accessibility under authentic usage conditions
- User decision-making patterns and support needs

### **Combined Learning Framework**
- Technical issues require traditional charter validation
- User experience concerns require scenario investigation
- Design improvements benefit from scenario insights
- Automation strategies incorporate both evidence types
- Risk assessment considers both technical and user experience factors

## Charter Lifecycle Management

### **Release-Driven Updates**
- **Refresh charters with every release** to ensure alignment with current functionality
- **New features** ‚Üí create new charters to investigate user experience and integration
- **Changed features** ‚Üí update existing charters to reflect new behaviour and workflows
- **Removed features** ‚Üí archive obsolete charters to maintain focus on delivered functionality

### **User Feedback Integration**
- **Adjust priorities** based on real user insights and support queries
- **Update scenarios** based on observed user behaviour patterns
- **Refine evidence frameworks** based on what investigations actually discover

### **Charter Review Triggers**
- **Every release** - systematic review of all charters
- **User feedback** - when support queries suggest charter gaps
- **Feature changes** - when delivered functionality changes significantly
- **Investigation insights** - when sessions reveal charter improvements needed

## Anti-Patterns to Avoid

### **‚ùå Story-by-Story Charters**
- Creates too many granular documents
- Increases cognitive overhead for investigators
- Misses cross-feature integration issues
- **Instead**: Group related functionality into meaningful themes

### **‚ùå Testing Planned Features**
- Charters become outdated when plans change
- Investigators waste time on non-existent functionality
- **Instead**: Focus exclusively on delivered, testable features

### **‚ùå Abstract Test Scenarios**
- Technical test steps don't reflect real user behaviour
- Miss authentic user pressures and environmental factors
- **Instead**: Structure around realistic user behaviour patterns and pressures

### **‚ùå Complex Evidence Notation**
- Cryptic symbols (+/-/?/!) reduce readability
- Make documentation harder to scan during sessions
- **Instead**: Use clear emoji headers and standard bullet points

### **‚ùå Fixed Charter Library**
- Charters become stale and disconnected from actual system
- Miss opportunities to investigate new functionality
- **Instead**: Evolve charters continuously with system changes

## Implementation Guidelines

### **When Creating New Charters**
1. **Identify the testing theme** - what specific concern does this address?
2. **Map to delivered features** - which actual features will be tested?
3. **Select primary personas** - who are the main users for this theme?
4. **Define realistic scenarios** - what authentic pressures and workflows apply?
5. **Structure evidence framework** - what signals, warnings, questions, and ideas are relevant?

### **When Updating Existing Charters**
1. **Review delivered features** - what has changed since last update?
2. **Update scenarios** - do activities still reflect current functionality?
3. **Refresh evidence framework** - are we looking for the right signals?
4. **Validate persona alignment** - do scenarios still serve the intended users?

## Success Indicators

### **Effective Charter Library**
- **Investigators can quickly select** appropriate charters for current concerns
- **Sessions consistently discover** actionable insights about user experience
- **Charters remain current** with delivered functionality
- **Cross-feature integration issues** are identified through realistic workflows

### **Quality Investigation Sessions**
- **60-90 minute duration** allows thorough but focused exploration
- **Realistic scenarios** reveal authentic user experience issues
- **Evidence collection** leads to specific improvement actions
- **Documentation** supports follow-up work and automation planning

This enhanced framework ensures our test charters provide both **technical validation** and **realistic user investigation**, delivering comprehensive evidence for quality decisions that serve real users effectively.
