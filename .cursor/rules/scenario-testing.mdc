---
description: when implementing realistic user scenarios, applying Bolton's testing framework, designing authentic user investigations, or creating scenario-enhanced test charters
globs: 
alwaysApply: false
---
# Scenario Testing Methodology - Bolton's Framework

## Philosophy: Breaking the Test Case Addiction

### **Beyond Test Cases**
Following Michael Bolton's principles, scenario testing **replaces scripted test cases** with rich, realistic user investigation. Instead of predetermined steps that miss real-world variation, we explore **authentic user situations** with guided flexibility.

### **Core Distinction**
- **Test Cases** → Binary pass/fail, predetermined steps, miss realistic complexity
- **Scenarios** → Rich investigation, guided flexibility, authentic user pressures

### **Quality Through Realism**
Scenario testing reveals **how well features serve real users under authentic conditions**, not just whether they function in idealised environments.

## Bolton's Framework Elements

### **THEME**
**Clear mission statement about realistic user situation**
- Connect to genuine user problems and business value
- Focus on authentic challenges users actually face
- Avoid artificial testing scenarios that don't reflect reality

#### **Marine Licensing Examples:**
- "Discover guidance gaps for users completely new to marine licensing"
- "Test system behaviour when case officers work under time pressure with interruptions"
- "Explore privacy consent decision-making under seasonal deadline pressure"

### **SETUP**
**Authentic user context, environment, and pressures**
- Realistic device configurations and environmental constraints
- Genuine emotional and situational pressures
- Authentic user background and knowledge levels

#### **Marine Licensing Context Elements:**
- **Persona authenticity** - Deep understanding of the official personas in `documentation/personas/` (Zofia/Amy/Fatima/Simon)
- **Environmental pressures** - Office noise, mobile usage, poor Wi-Fi, interruptions
- **Technology context** - Assistive technology, device switching, browser limitations
- **Regulatory complexity** - Unfamiliar terminology, multiple guidance documents
- **Time pressures** - Seasonal deadlines, end-of-day urgency, project dependencies

### **ACTIVITIES**
**Guided but flexible realistic actions**
- What users would actually do, not idealised paths
- Adapt to discoveries while maintaining persona authenticity
- Include realistic mistakes, confusion, and help-seeking behaviour

#### **Realistic User Behaviours:**
- **Novice patterns** - Skipping guidance initially, trial-and-error learning, second-guessing decisions
- **Veteran patterns** - Efficiency shortcuts, data reuse expectations, pattern matching
- **Pressure responses** - Rushing through forms, making quick decisions, seeking help under time constraints
- **Error recovery** - Going back to change answers, starting over after confusion

### **ORACLES**
**Multiple quality indicators beyond functional correctness**
- User experience signals and warning signs
- Business value and efficiency indicators
- Content effectiveness and clarity measures

#### **Marine Licensing Oracles:**

##### **User Experience Quality:**
- **Terminology clarity** - Marine licensing terms explained in accessible language
- **Progressive guidance** - Help appears contextually when needed
- **Error prevention** - Interface prevents common novice mistakes
- **Recovery support** - Clear path back from errors without losing progress
- **Confidence building** - User feels guided and supported, not abandoned

##### **Warning Signs:**
- **Cognitive overload** - Too much information presented simultaneously
- **Assumed knowledge** - Interface expects familiarity with marine licensing processes
- **Hidden functionality** - Key features not discoverable through normal interaction
- **Frustration patterns** - User becomes stuck and considers abandoning application

### **VARIATIONS**
**Introduce realistic turbulence and stress**
- Test system behaviour under authentic pressure
- Explore edge cases through realistic scenarios
- Simulate real-world friction and complications

#### **Marine Licensing Variations:**
- **Technology friction** - Slow connections, browser crashes, battery issues
- **Interruption patterns** - Phone calls, colleague questions, urgent emails
- **Information challenges** - Terminology confusion, guidance complexity, multiple resources
- **Device switching** - Mobile-to-desktop workflows, assistive technology transitions
- **Time pressure escalation** - Approaching deadlines, end-of-day urgency

## Evidence Collection Framework

### **Discovery Documentation Categories**

#### **User Journey Evidence**
- **Decision points** - Where does user hesitate or show uncertainty?
- **Friction points** - What slows down or confuses the user journey?
- **Cognitive load** - Which parts require too much mental effort?
- **Help-seeking behaviour** - When and how does user try to get assistance?

#### **Content Effectiveness Evidence**
- **Language clarity** - Which terms cause confusion for domain novices?
- **Guidance effectiveness** - Does helper text actually help or add noise?
- **Example quality** - Are provided examples helpful and realistic?
- **Progress communication** - Does user understand where they are in process?

#### **Technical Integration Evidence**
- **Performance impact** - How does system behaviour change under realistic usage?
- **Data integrity** - Is information preserved accurately across realistic scenarios?
- **Integration reliability** - Do external systems work under authentic pressure?
- **Accessibility reality** - How does assistive technology work in real situations?

### **Problem Classification System**

#### **Critical Issues (Immediate Attention)**
- User cannot complete task due to barriers discovered under realistic conditions
- Complete confusion about requirements leading to abandonment
- Data loss during realistic usage patterns (interruptions, device switching)
- Interface design that systematically misleads users under pressure

#### **Significant Issues (High Priority)**
- Workflow inefficiencies that significantly impact real user success
- Content or interface elements that create confusion under authentic conditions
- Performance issues that disrupt flow during realistic usage
- Accessibility barriers revealed through authentic assistive technology usage

#### **Improvement Opportunities (Medium Priority)**
- Content that could be clearer for realistic user contexts
- Interface refinements that would improve efficiency under pressure
- Additional help options that would reduce anxiety in authentic situations
- Cross-device experience enhancements for realistic workflows

## Marine Licensing Scenario Implementation

### **Persona-Driven Scenarios**
Using the established personas from `documentation/personas/` to create authentic scenarios:

#### **Zofia (Novice Applicant) Scenarios**
- **Authentic confusion** - First marine licensing application, unfamiliar terminology
- **Technology challenges** - Screen reader usage, mobile-to-desktop switching
- **Time pressure** - Project approval needed before seasonal restrictions
- **Information overload** - Multiple guidance documents, complex requirements

#### **Amy (Veteran Applicant) Scenarios**  
- **Efficiency focus** - Quick completion expectations, keyboard shortcuts
- **Pattern matching** - Expectations based on previous government services
- **Data reuse** - Expecting to use information from previous applications
- **Workflow optimization** - Looking for faster paths through familiar processes

#### **Fatima (Case Officer) Scenarios**
- **Multitasking pressure** - Multiple applications, external system integration
- **Interruption management** - Phone calls, colleague questions, urgent requests
- **Decision consistency** - Comparing applications for uniform decision-making
- **Quality maintenance** - Accuracy requirements despite time pressure

#### **Simon (Marine Officer) Scenarios**
- **Technical focus** - Compliance validation, environmental integration
- **Field context** - Mobile access, poor connectivity, outdoor conditions
- **Specialist knowledge** - Deep technical understanding but interface complexity
- **Stakeholder pressure** - Planning departments, environmental agencies requiring consultation

### **Realistic Pressure Simulation**

#### **Time Pressure Implementation**
- **Seasonal deadlines** - Wildlife restrictions, tidal windows
- **End-of-day urgency** - Decision deadlines, office closing times
- **Project dependencies** - Contractors waiting, planning permission coordination
- **Financial pressure** - Project costs accumulating during approval delays

#### **Interruption Simulation**
- **Phone call patterns** - 5-15 minute interruptions requiring attention switch
- **Colleague questions** - Brief 2-5 minute consultations about complex cases
- **System alerts** - External database issues, integration failures
- **Email urgency** - High-priority messages requiring immediate response

#### **Technology Friction**
- **Network issues** - Slow connections, timeouts, intermittent availability
- **Device limitations** - Battery life, screen size, processing power
- **Browser problems** - Tab crashes, autofill conflicts, plugin issues
- **Assistive technology** - Screen reader interaction, keyboard navigation challenges

## Integration with Session-Based Testing

### **Scenario-Enhanced SBTM Structure**

#### **Setup Phase (15 minutes)**
- Configure realistic persona context and pressures
- Set up devices, assistive technology, interruption simulations
- Prepare scenario-specific test data and materials
- Review persona background and motivations

#### **Investigation Phase (75-90 minutes)**
- Execute scenario activities with persona authenticity
- Follow realistic user patterns and friction simulation
- Apply scenario oracles and quality indicators
- Document discoveries using scenario evidence framework
- Adapt to findings while staying in character

#### **Wrap-up Phase (15 minutes)**
- Assess scenario completion and key discoveries
- Document evidence using classification system
- Note which variations were most revealing
- Identify follow-up traditional testing needs

### **Session Documentation**

#### **Scenario Session Notes**
- **Persona authenticity** - How well did the scenario reflect real user context?
- **Pressure effectiveness** - Which realistic pressures revealed most issues?
- **Oracle application** - What quality indicators proved most valuable?
- **Variation impact** - Which turbulence introduced meaningful discoveries?

#### **Evidence Quality Assessment**
- **Discovery depth** - What insights wouldn't traditional testing reveal?
- **User empathy** - How well does evidence represent real user experience?
- **Business value** - What improvements would most benefit authentic users?
- **Technical integration** - What traditional testing is needed to validate findings?

## Automation Integration

### **Scenario Insights for Automation**
- **Realistic user patterns** - Which behaviours should automation validate?
- **Edge case discovery** - What scenarios revealed gaps in automated coverage?
- **Performance benchmarks** - What realistic usage patterns need monitoring?
- **Accessibility validation** - How can automation support assistive technology scenarios?

### **Automation Limitations**
Scenarios reveal quality aspects automation cannot validate:
- **Content clarity** - Whether guidance actually helps real users
- **Cognitive load** - Mental effort required under realistic pressure
- **Emotional response** - User confidence, anxiety, frustration patterns
- **Context switching** - Recovery from realistic interruptions and distractions

## Quality Assurance Principles

### **Scenario Authenticity**
- **Genuine user problems** - Address real challenges, not invented scenarios
- **Realistic pressure** - Authentic time, environmental, and cognitive constraints
- **Persona fidelity** - True to character throughout investigation
- **Evidence integrity** - Document what actually happened, not what should have happened

### **Investigation Balance**
- **Guided structure** - Clear mission and framework for investigation
- **Adaptive flexibility** - Adjust to discoveries while maintaining authenticity
- **Systematic evidence** - Consistent documentation and classification
- **Learning integration** - Connect findings to design improvements and traditional testing needs

This methodology ensures scenario testing provides **authentic user experience evidence** that complements traditional technical validation, revealing how well marine licensing features actually serve real users under genuine conditions.
